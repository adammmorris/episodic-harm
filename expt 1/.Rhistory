pt(t.stat, N - J - 1)
2 * pt(t.stat, N - J - 1, lower.tail = F)
.114 ^ 2
.073 ^ 2
.073 ^ 2 * N / (N - 1)
.073 ^ 2 * (N - 1) / N
t.stat <- b / se.b
b <- .115 * .114 / 1.059
# We need to calculate the standard error of the unstandarized coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate <- sqrt(ss.res / N)
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b <- sqrt((se.estimate ^ 2) / (ss.sdo * tol.sdo))
t.stat <- b / se.b
2 * pt(t.stat, N - J - 1, lower.tail = F)
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# That semi-partial correlation is a measure of the relationship between
# affirmative action opposition and education, controlling for the
# effect of SDO on education.
# It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(MASS)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(ez)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
200 * .7
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
rm(list=ls())
N <- 361 # sample size
J <- 7 # number of predictors
ss.reg <- 59.69 # sum of squares of regression model
ss.res <- 344.25 # sum of squares of residuals
ms.reg <- ss.reg / J # mean-square regression
ms.res <- ss.res / (N - J - 1) # mean-square residuals
## 3a.
# What % of the variation in opposition to affirmative action can be explained
# by the other variables?
# The % of variance explained by all of them is R-squared, which is
# SS-reg / (SS-reg + SS-res), or...
rsq <- ss.reg / (ss.reg + ss.res) # .15
# The % of variance that can be explained by each predictor (NOT controlling
# for other variables) is the square of the zero-order correlations, or...
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
# in the order on the homework:
# .055 .072 .0017 .0083 .019 .0059 .030
# The % of variance that can be explained by each predictor (controlling for the
# effects of the other predictors on this predictor) is the square of the semi-partial correlation
# between opposition to affirmative action and the predictor (available in the output), or..
c(.179, .178, -.029, .121, .0884, -.0347, .105) ^ 2
# in the order on the homework:
# .032 .032 .00084 .015 .0078 .0012 .011
f.stat <- ms.reg / ms.res
# and get the p value by using the F distribution function...
pf(f.stat, J, N - J - 1, lower.tail = F)
rsq.adj <- 1 - (1 - rsq) * (N - 1) / (N - J - 1) # .13
var.res <- ss.res / (N - J - 1) # .98
.0884 ^ 2 # .0078
b.educ <- .143 * 1.059 / 1.618
# then, calculate a t statistic by t(N - J - 1) = b / std-error(b), pulling std-error(b) from the
# output, or...
t.stat.educ <- b.educ / .038
# finally, get the (2-tailed) p value by looking up this value in the t distribution
2 * pt(t.stat.educ, N - J - 1, lower.tail = FALSE) # .014
# p < .05; opposition to affirmative action can be predicted by education at an above-chance level
## 3g.
# Same explanation as above.
b.sdo <- .115 * 1.059 / .114
# As it's not in the output, this time we need to calculate the standard error of the unstandarized
# coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate.sdo <- sqrt(ss.res / N) # .98
se.estimate.sdo <- sqrt(ss.res / N) # .98
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b.sdo <- sqrt((se.estimate.sdo ^ 2) / (ss.sdo * tol.sdo)) # .49
t.stat.sdo <- b.sdo / se.b.sdo # 2.18
2 * pt(t.stat.sdo, N - J - 1, lower.tail = FALSE) # .030
# p < .05; opposition to affirmative action can be predicted by SDO at an above-chance level
## 3h.
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# This semi-partial correlation is a measure of the relationship between affirmative action
# opposition and education, controlling for the effect of SDO on education. It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2) # .13
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
setwd("~/Me/Psychology/Projects/DYNA/git/Data/Explicit/Summary/help_vs_harm")
require(ggplot2)
require(lme4)
require(lmerTest)
require(dplyr)
require(RColorBrewer)
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
se <- function(data) {return(sd(data)/sqrt(length(data)))}
data.raw <- read.csv("data.csv")
data <- arrange(data.raw, subject)
data$imagine <- factor(data$imagine, labels = c("Control", "Imagine"), levels = c(0,1))
data$condition <- factor(data$condition, labels = c("Harm","Help"), levels = c(0,1))
data$rationalization <- factor(data$rationalization, levels = c(0,1), labels = c("No", "Yes"))
data$story_ind <- factor(data$story, labels = 1:14)
## exclusion
exclude.subj <- (data %>% group_by(subject) %>%
summarise(nResponses = length(response), respLength = mean(nchar(encodeString(as.character(na.omit(response)))))) %>%
filter(respLength < 50 | nResponses != 14))$subject
df.filt <- data %>% tbl_df %>%
filter(!(subject %in% exclude.subj))
## collapse data
df.wide <- df.filt %>% group_by(condition, imagine, subject) %>%
summarise(rating_will = mean(rating))
df.collapsed <- df.wide %>% group_by(condition, imagine) %>%
summarise(will = mean(rating_will), will.se = se(rating_will))
## main test: willingness ~ condition * imagine
hist(df.filt$rating)
table(df.filt$condition, df.filt$imagine)
ggplot(df.collapsed, aes(x = imagine, y = will, colour = condition, group = condition)) +
geom_line(aes(), size = 1) +
geom_point(aes(), size = 5) +
geom_errorbar(aes(ymax = will + will.se, ymin = will - will.se), width = .1) +
labs(x = "", y = "Likelihood of performing behavior") +
theme(axis.title.y = element_text(vjust = 1)) +
guides(linetype = guide_legend(title = "Condition"),
colour = guide_legend(title = "Condition"),
shape = guide_legend(title = "Condition")) +
ylim(2, 7)
model.likelihood <- lmer(rating ~ condition * imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
summary(model.likelihood)
model.likelihood.null <- lmer(rating ~ condition + imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
model.likelihood.null2 <- lmer(rating ~ condition + condition:imagine (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
model.likelihood.null2 <- lmer(rating ~ condition + condition:imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
anova(model.likelihood, model.likelihood.null)
?lmer
anova(model.likelihood, model.likelihood.null2)
model.likelihood <- lmer(rating ~ condition * imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt, REML = F)
model.likelihood.null2 <- lmer(rating ~ condition + condition:imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt, REML = F)
anova(model.likelihood, model.likelihood.null2)
summary(model.likelihood.null2)
length(exclude.subj)
table(df.filt$condition, df.filt$imagine)
table(df.filt$condition, df.wide$imagine)
table(df.wide$condition, df.wide$imagine)
model.likelihood.null2 <- lmer(rating ~ condition + conditionHelp:imagineImagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt, REML = F)
model.likelihood.null2 <- lmer(rating ~ condition * imagine - imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt, REML = F)
summary(model.likelihood.null2)
model.likelihood.null2 <- lmer(rating ~ condition * imagine - imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
summary(model.likelihood.null2)
require(ez)
plot(allEffects(model.likelihood))
require(effects)
install.packages("effects")
require(effects)
plot(allEffects(model.likelihood))
require(pbkrtest)
model <- lmer(rating ~ condition * imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
model.noint <- lmer(rating ~ condition + imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
KRmodcomp(model, model.noint)
PBmodcomp(model, model.noint)
anova(model, model.noint)
model <- lmer(rating ~ condition + imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
summary(model.noint)
model.onlycond <- lmer(rating ~ condition + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
anova(model.noint, model.onlycond)
summary(model.noint)
anova(model.noint, model.onlycond)
summary(model.noint)
anova(model.noint, model.onlyimag) # main effect of imagine (chisq(1) = 6.49, p = .01)
model.onlyimag <- lmer(rating ~ imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
anova(model.noint, model.onlyimag) # main effect of imagine (chisq(1) = 6.49, p = .01)
ggplot(df.collapsed, aes(x = imagine, y = will, colour = condition, group = condition)) +
geom_line(aes(), size = 1) +
geom_point(aes(), size = 5) +
geom_errorbar(aes(ymax = will + will.se, ymin = will - will.se), width = .1) +
labs(x = "", y = "Likelihood of performing behavior") +
theme(axis.title.y = element_text(vjust = 1)) +
guides(linetype = guide_legend(title = "Condition"),
colour = guide_legend(title = "Condition"),
shape = guide_legend(title = "Condition")) +
ylim(2, 7)
setwd("~/Me/Psychology/Projects/DYNA/git/Data/Explicit/Summary/harm_combined/within")
rm(list=ls())
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
se <- function(data) {return(sd(data)/sqrt(length(data)))}
dodge <- position_dodge(width=0.9)
## import data
data.raw <- read.csv("data.csv")
data <- arrange(data.raw, subject)
data$imagine <- factor(data$imagine, labels = c("Control", "Imagine"), levels = c(0,1))
data$condition <- factor(data$condition, labels = c("Positive","Negative","Neutral"), levels = c(2,0,1))
## exclusion
exclude.subj <- (data %>% group_by(subject) %>%
summarise(nResponses = length(response), respLength = mean(nchar(encodeString(as.character(na.omit(response)))))) %>%
filter(respLength < 50))$subject
df.filt <- data %>% tbl_df %>%
filter(!(subject %in% exclude.subj) & version != 'explicit_v6' & version != 'explicit_v8')
## collapse data
df.wide <- df.filt %>% group_by(condition, imagine, subject) %>%
summarise(rating_will = mean(rating_will), rating_happy = mean(rating_happy), rating_detail = mean(rating_detail), rating_cohere = mean(rating_cohere))
df.collapsed <- df.wide %>% group_by(condition, imagine) %>%
summarise(will = mean(rating_will), will.se = se(rating_will),
happy = mean(rating_happy), happy.se = se(rating_happy),
detail = mean(rating_detail), detail.se = se(rating_detail),
cohere = mean(rating_cohere), cohere.se = se(rating_cohere))
## main test: willingness ~ condition * imagine
hist(df.filt$rating_will)
table(df.filt$condition, df.filt$imagine)
ggplot(df.collapsed, aes(x = imagine, y = will, colour = condition, group = condition)) +
geom_line(aes(), size = 1) +
geom_point(aes(), size = 5) +
geom_errorbar(aes(ymax = will + will.se, ymin = will - will.se), width = .1) +
labs(x = "", y = "Likelihood of performing behavior") +
theme(axis.title.y = element_text(vjust = 1)) +
guides(linetype = guide_legend(title = "Condition"),
colour = guide_legend(title = "Condition"),
shape = guide_legend(title = "Condition")) +
ylim(2, 7) + scale_colour_manual(values = c("Positive" = "Darkgreen", "Negative" = "Red", "Neutral" = "Blue"))
load("~/Me/Psychology/Projects/DYNA/git/Data/Explicit/Summary/harm_combined/within/analysis.RData")
summary(model.likelihood)
require(lmerTest)
summary(model.likelihood)
model.likelihood <- lmer(rating_will ~ condition * imagine + (1 + imagine | subject) + (1 + condition + imagine | story_id),
data = df.filt %>% filter(condition != 'Neutral'))
summary(model.likelihood)
rm(list=ls())
setwd("~/Me/Psychology/Projects/DYNA/git/Data/Explicit/Summary/help_vs_harm")
require(ggplot2)
require(lme4)
require(lmerTest)
require(dplyr)
require(pbkrtest)
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
se <- function(data) {return(sd(data)/sqrt(length(data)))}
## import data
data.raw <- read.csv("data.csv")
data <- arrange(data.raw, subject)
data$imagine <- factor(data$imagine, labels = c("Control", "Imagine"), levels = c(0,1))
data$condition <- factor(data$condition, labels = c("Harm","Help"), levels = c(0,1))
data$rationalization <- factor(data$rationalization, levels = c(0,1), labels = c("No", "Yes"))
data$story_ind <- factor(data$story, labels = 1:14)
## exclusion
exclude.subj <- (data %>% group_by(subject) %>%
summarise(nResponses = length(response), respLength = mean(nchar(encodeString(as.character(na.omit(response)))))) %>%
filter(respLength < 50 | nResponses != 14))$subject
df.filt <- data %>% tbl_df %>%
filter(!(subject %in% exclude.subj))
## collapse data
df.wide <- df.filt %>% group_by(condition, imagine, subject) %>%
summarise(rating_will = mean(rating))
df.collapsed <- df.wide %>% group_by(condition, imagine) %>%
summarise(will = mean(rating_will), will.se = se(rating_will))
## main test: willingness ~ condition * imagine
hist(df.filt$rating)
table(df.wide$condition, df.wide$imagine)
ggplot(df.collapsed, aes(x = imagine, y = will, colour = condition, group = condition)) +
geom_line(aes(), size = 1) +
geom_point(aes(), size = 5) +
geom_errorbar(aes(ymax = will + will.se, ymin = will - will.se), width = .1) +
labs(x = "", y = "Likelihood of performing behavior") +
theme(axis.title.y = element_text(vjust = 1)) +
guides(linetype = guide_legend(title = "Condition"),
colour = guide_legend(title = "Condition"),
shape = guide_legend(title = "Condition")) +
ylim(2, 7)
# test for interaction
model <- lmer(rating ~ condition * imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
summary(model)
summary(model.noint)
model.noint <- lmer(rating ~ condition + imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
summary(model.noint)
contrasts(df.filt$imagine)
contrasts(df.filt$condition)
rm(list=ls())
if (!require(pastecs)) {install.packages("pastecs"); require(pastecs)}
if (!require(reshape)) {install.packages("reshape"); require(reshape)}
if (!require(lattice)) {install.packages("lattice"); require(lattice)}
if (!require(car)) {install.packages("car"); require(car)}
if (!require(dae)) {install.packages("dae"); require(dae)}
if (!require(nlme)) {install.packages("nlme"); require(nmle)}
if (!require(ez)) {install.packages("ez"); require(ez)}
if (!require(WRS2)) {install.packages("WRS2"); require(WRS2)}
#----- Functions ------#
# Note: by "intuitive" contrasts, I mean those that directly specify the weighted group means
# Creates a contrast matrix from an "intuitive" list of contrast vectors
# Adam Morris, 11/5/2015
makeContrastMatrix <- function(contrast.list) {
nLevels <- length(contrast.list[[1]])
if (length(contrast.list) != (nLevels - 1)) stop("contrast.list must specify nLevels - 1 contrasts, where nLevels is the number of levels in your factor.")
intuitive.coding <- cbind(rep(1/nLevels, nLevels), sapply(contrast.list, cbind))
return(solve(t(intuitive.coding))[, -1])
}
# Extracts an "intuitive" contrast list from a well-formed matrix (i.e. one that you would get from the output of model fitting)
# Adam Morris, 11/5/2015
extractContrastMatrix <- function(contrast.matrix) {
intuitive.matrix <- t(solve(cbind(rep(1,nrow(contrasts$vintage)), contrasts$vintage)))[, -1]
return(split(intuitive.matrix, col(intuitive.matrix)))
}
# Better interaction plot
# Adam Morris, 11/5/2015
intPlot <- function(factor1, factor2, dv, colors, title, reverse, colors2, title2) {
# defaults
if (missing(reverse)) reverse = F;
if (missing(colors)) colors = 1:length(factor2);
if (missing(title)) title = paste(deparse(substitute(factor1)), " x ", deparse(substitute(factor2)));
if (reverse) {
if (missing(title2)) title2 = paste(deparse(substitute(factor2)), " x ", deparse(substitute(factor1)));
op <- par(mfrow = c(1,2))
interaction.plot(factor1, factor2, dv, lty = 1, col = colors, main = title, legend = F, type = "b", pch = 19)
legend("bottomright", legend = levels(factor2), col = colors, lty = 1, cex = 0.8)
intPlot(factor2, factor1, dv, colors2, title2, reverse = F);
par(op)
} else {
interaction.plot(factor1, factor2, dv, lty = 1, col = colors, main = title, legend = F, type = "b", pch = 19)
legend("bottomright", legend = levels(factor2), col = colors, lty = 1, cex = 0.8)
}
}
set.seed(123);
df <- read.csv("http://markallenthornton.com/data/misc/winecom.csv")
str(df) # N = 160
head(df)
rm(list=ls())
?lsmeans
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
se <- function(data) {return(sd(data)/sqrt(length(data)))}
## import data
data.raw <- read.csv("data.csv")
data <- arrange(data.raw, subject)
data$imagine <- factor(data$imagine, labels = c("Control", "Imagine"), levels = c(0,1))
data$condition <- factor(data$condition, labels = c("Harm","Help"), levels = c(0,1))
data$rationalization <- factor(data$rationalization, levels = c(0,1), labels = c("No", "Yes"))
data$story_ind <- factor(data$story, labels = 1:14)
## exclusion
exclude.subj <- (data %>% group_by(subject) %>%
summarise(nResponses = length(response), respLength = mean(nchar(encodeString(as.character(na.omit(response)))))) %>%
filter(respLength < 50 | nResponses != 14))$subject
df.filt <- data %>% tbl_df %>%
filter(!(subject %in% exclude.subj))
## collapse data
df.wide <- df.filt %>% group_by(condition, imagine, subject) %>%
summarise(rating_will = mean(rating))
df.collapsed <- df.wide %>% group_by(condition, imagine) %>%
summarise(will = mean(rating_will), will.se = se(rating_will))
## main test: willingness ~ condition * imagine
hist(df.filt$rating)
table(df.wide$condition, df.wide$imagine)
ggplot(df.collapsed, aes(x = imagine, y = will, colour = condition, group = condition)) +
geom_line(aes(), size = 1) +
geom_point(aes(), size = 5) +
geom_errorbar(aes(ymax = will + will.se, ymin = will - will.se), width = .1) +
labs(x = "", y = "Likelihood of performing behavior") +
theme(axis.title.y = element_text(vjust = 1)) +
guides(linetype = guide_legend(title = "Condition"),
colour = guide_legend(title = "Condition"),
shape = guide_legend(title = "Condition")) +
ylim(2, 7)
# test for interaction
model <- lmer(rating ~ condition * imagine + (1 + imagine | subject) + (1 + condition * imagine | story_ind), data = df.filt)
lsmeans(model, pairwise ~ condition * imagine, adjust = "tukey")
?lsmeans
lsmeans(model, adjust = "tukey")
lsmeans(model, test.effs = "condition * imagine" adjust = "tukey")
lsmeans(model, test.effs = "condition * imagine", adjust = "tukey")
lsmeans(model, test.effs = c("condition", "imagine", "condition:imagine"), adjust = "tukey")
require(multcomp)
installed.packages("multcomp")
install.packages("multcomp")
install.packages("multcomp")
